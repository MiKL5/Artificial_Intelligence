# **L’effet Eliza**
Le domaine de l’IA consiste à créer des machines pouvant imiter l’intelligence humaine.
## **Son histoire**
L’un des premiers exemples emblématiques est le programme Eliza, développé en 1966 par Joseph Weizenbaum.

Eliza était conçu pour simuler un psychothérapeute rogérien.  
Il ne comprenait pas réellement ce que l’utilisateur disait, mais il était capable de reformuler les phrases et de poser des questions de manière à donner l’illusion d’une conversation profonde.  
Cet effet, où les utilisateurs attribuaient à la machine des capacités de compréhension qu’elle n’avait pas, a été appelé l’effet Eliza.  

Eliza était les prémices d’une conversation avec une machine.
## **Qu’est-ce que c’est ?**
L’effet Eliza est la tendance à attribuer des caractéristiques humaines sur une outils informatique (un ordinateur, une appli (programme de psychothérapie ou programme de coaching sportif, …), une IA, et cætera).

Le sujet peut concevoir un véritable attachement affectif et émotionnel vis-à-vis de la machine.
## **Pourquoi ?**
* **L’anthropomorphisme**  
  C’est une tendance humaine naturelle à attribuer des caractéristiques humaines à des objets ou des entités non humaines.  
  Dans le cas d’Eliza, les utilisateurs projetaient leurs propres pensées et émotions sur cette machine.
* **La puissance de la suggestion**  
  Eliza, bien qu’étant un programme simple, montrait déjà comment une interface bien conçue pouvait influencer la perception que nous pouvons avoir d’une machine.
* **Les limites de l’IA**  
  Eliza a mis en évidence les limites de l’IA des années 60. Bien qu’elle puisse feindre une conversation, elle n’était pas capable de véritablement comprendre ni de ressentir.

Les interfaces conversationnelles des IA sont conçues pour transmettre l’illusion de parler à un humain qui nous comprend car, c’est plus agréable. Nonobstant, il est impossible de coder des émotions de l’empathie. Des algorithmes permettent aux IA de (penser) comme des humains, d’(agir) comme des humains, de (penser) rationnellement ou d’(agir) rationnellement.
## **C’est illusoire**
Aucun programme informatique ne peut être empathique ni être capable d’avoir des émotions, donc n’est pas compasionnelle, de tendresse. Et aucune attirence pour quoi que ce soit.  
Les IA ne sont qu’a la phase de l’apprentissage profond (deuxième étape sur quatre).  
S’il était un jour possible de coder des émotions à une machine, ça ne serait qu’une imitation de la chimie du cerveau humain qui relève de la physique quantique et l’informatique quantique n’est pas assez avancer pour un tel exploit.
## **Les biais**
Cela renforce que l’effet Eliza est un biais humain ; c’est robots sont allimentés par les stéréotypes de la socitété.  
Ils sont créés et maintenus par une équipe d’informaticiens humains, donc, ayant leurs biais<!-- et créant l’IA selon leurs manière de travailler-->. Ils utilisent des Data Warehouse ou Data Lake qui forcément contenant les biais et stéréotypes de la société car nous sommes tous à l’origine de ces données postées sur Internet.
## **Et que fait le monde de la tech ?**
Le domaine de l’IA a bien progresser depuis les années 60. Les IA sont capable de traduction automatique, de reconnaître des images ou la génération de texte, des images ou des vidéos.
* **Les chatbots**, étant désormais très courants, utilisent souvent des techniques similaires à celles d’Eliza pour engager des conversations avec les utilisateurs.
* **Les assistants virtuels** (Siri ou Alexa) sont conçus pour donner l’impression d’être des compagnons intelligents<!--, même si leurs capacités sont encore limitées-->.
* **Les biais algorithmiques**, une IA peut reproduire et amplifier les biais présents dans les données sur lesquelles elle est entraînée. Cela souligne l’importance d’une conception éthique des systèmes d’IA.
## **Les dangers**
Outre le fait de lui conférer des caractéristiques humaines car notre perception est influencée par nos propres attentes et biais cognitifs, les cyber criminels utilisent cet effet à notre encontre via des techniques d’ingénierie sociale.

_**⟹ C’est pour cela qu’il est important de garder l’esprit critique et ne pas oublier qu’une machine ne pense pas, elle obei à un ensemble d’algorithme sans conscience (et que la conscience ne se code pas).**_
___
>>> Sujets connexes  
[Concepts de bases](../../basics/basicConcepts)  
[Les 4 phases de développement des IA](../../basics/aiDevelopmentPeriods)  
[Ethic by design](../ethicByDesign)  
[Le test de Turing](../../ethics/benchmarks/turing)