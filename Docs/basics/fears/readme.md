# **Les craintes**

* ### La peur de la singularité technologique  
  La machine apprend d'elle-même, et plus elle apprend, plus il peut nous devenir compliqué de comprendre son apprentissage ainsi que d'en garder la maîtrise. Et donc la peur qu'elle devienne plus forte que l'Homme.
  Bien qu'actuellement les IA soient très performantes, elles sont très spécialisées (médecine, reconnaissance d'image). Aucune AI ne sait agir dans plusieurs domaines.
  
  Par ailleurs, il est toujours impossible de lui construire une conscience. Il y a également quatre lois qui sont les bases de [la gestion des risques](../../basics/riskManagement "La gestion des risques") liés à l'IA. Ainsi que les principes : [ethic by design](../../basics/ethicByDesign), [privacy by design](../../basics/privacyByDesign), [privacy by default](../../basics/privacyByDefault) qui permettent de coder des IA respectant l'être humain ainsi que sa confidentialité.
* ### La menace sur certains emplois  
  Les métiers non qualifiés, aux tâches simples, répétitives et pouvant être effectué par l'IA sont menacés.
  Cela fait émerger des emplois dans la data, tel que data analyst, data scientist, data engineer.
* ### Le risque de détournement et de malveillance  
  Les internautes peuvent apprendre des grossièretés aux chatbots, jusqu'aux propos racistes, ce qui biaise des IA jusqu'à devenir malveillantes. Le principe [ethic by design](../../basics/ethicByDesign) sus-cité vient réduire ce risque. Car il impose aux systèmes d'IA d'êtres équitables et non discriminatoires.
* ### Son fonctionnement est nébuleux 
  Le fait de ne pas savoir comment elle réalise une tâche.  
  C'est-à-dire qu'on la nourrit de données en entrée. On voit ce qu'il en ressort. Mais que se passe-t-il au milieu ? Ça ne se voit pas.  
  Au final, ça reste une logique algorithmique dont l'utilisateur n'a aucune maîtrise.
* ### La menace sur la vie privée
  Malgré le RGPD, plus l'intelligence artificielle apprend de l'utilisateur, plus elle devient efficace.  
  En effet, c'est avant tout un agent qui traite d'immenses bases de données de façon algorithmique. Chaque utilisateur à son agent qui a pour savoir ces bases de données ainsi que les propos qu'il lu tient.  
  L'[ethic by design](../../basics/ethicByDesign), le [privacy by design](../../basics/privacyByDesign), ainsi que [privacy by default](../../basics/privacyByDefault) permettent à l'utilisateur d'accordé une certaine confiance en cet agent. Nonobstant, le but de l'IA est de correspondre aux attentes du public. Ainsi, une IA génératrice d'image aura tendance à proposer des résultats plus pertinents au fur et à mesure. Les IA conversationnelles telles que "ChatGPT" ou "Gemini" en font de même. En d'autres termes, pour obtenir l'IA-art que j'imagine, je dois donner un contexte afin que le résultat final si approche le plus.

> Conclusion  
**L'utilisateur reste seul responsable des infos qu'il donne** et qui ne **lui appartient plus**, ainsi que de **ce qu'il demande** et **le contexte du prompt**, car ce contexte _**influence le résultat**_, donc _**le comportement de cet agent face à l'utilisateur et ce qu'il lui répond**_.  
>
> La meilleure protection vient de la posture de l'utilisateur face à l'IA. Elle évoluera grâce aux types de données qui sont fournies et aux usages.
>
> La machine ne pourra jamais tout faire. Le robot aspirateur n'a pas remplacé le balai.

<!-- >> Pour aller plus loin  
Le livre de Jean-Claude HEUDIN pour [Comprendre le deep learining](https://www.amazon.fr/Comprendre-Deep-Learning-introduction-neurones/dp/B01MSFLMFD/ref=sr_1_1?dib=eyJ2IjoiMSJ9.fQPZjayTRtT_bMdlcNPPMstt4wx7J99qFNG4Rv9qGScgzhRwcm6c5s6X5OMn2zxWis6HW3K_HF_N_dGsOtWdtmINwixIjWTyYInyghE1UVjazAWDZD_boeo_PSEQwRX7xgaF6UIk5uqbOBlfZoACog.erLtoHVeyv5z3yIoUbc9tPQtDDMgOSe5iN0QJ6wcPCk&dib_tag=se&qid=1705095227&refinements=p_27%3AJean-Claude+Heudin&s=books&sr=1-1) -->